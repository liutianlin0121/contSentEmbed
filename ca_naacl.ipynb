{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ca_naacl.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-iBDcnClM7b5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Continual Learning for Sentence Representations Using Conceptors"
      ]
    },
    {
      "metadata": {
        "id": "-1m5aRpwf877",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some prepartion"
      ]
    },
    {
      "metadata": {
        "id": "h2yftonGgdmJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  load packages\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qZqK1z9zgaE8",
        "colab_type": "code",
        "outputId": "7c7cca79-2017-43a4-f535-33988c19e0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# using colab usage\n",
        "  \n",
        "!pip install -q gdown\n",
        "!pip install -q gensim\n",
        "!pip install -q pandas scipy seaborn\n",
        "\n",
        "\n",
        "resourceFile = '/content/'\n",
        "\n",
        "\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import math\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('punkt')\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cUN7JCp5goIF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### load word vectors\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JWHCreaogrZk",
        "colab_type": "code",
        "outputId": "b7077968-7efd-46c2-b936-184b33101900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load glove word vector\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
        "  \n",
        "glove = KeyedVectors.load_word2vec_format(resourceFile + 'gensim_glove.840B.300d.txt.bin', binary=True)\n",
        "print('The glove embedding has been loaded!')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:58, 45.2MB/s]\n",
            "The glove embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_OcIeY_BM7cD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### load STS Benchmark\n",
        "\n",
        "The STS Benchmark brings together the English data from the SemEval sentence similarity taskshttp://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark and \n",
        " http://ixa2.si.ehu.es/stswiki/images/e/ee/Stscompanion.tar.gz\n"
      ]
    },
    {
      "metadata": {
        "id": "XUEMfkhxM7cF",
        "colab_type": "code",
        "outputId": "ec9afd02-b8bc-4eb2-a747-b7f95797172d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz # STS\n",
        "!tar xvzf Stsbenchmark.tar.gz\n",
        "\n",
        "!wget http://ixa2.si.ehu.es/stswiki/images/e/ee/Stscompanion.tar.gz # STS companian\n",
        "!tar xvzf Stscompanion.tar.gz\n",
        "  \n",
        "  \n",
        "\n",
        "def load_sts_dataset(filename):\n",
        "    # For a STS dataset, loads the relevant information: the sentences and their human rated similarity score.\n",
        "    sent_pairs = []\n",
        "    with tf.gfile.GFile(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            ts = line.strip().split(\"\\t\")\n",
        "            #sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
        "            if len(ts) == 7 or len(ts) == 9:\n",
        "                sent_pairs.append((re.sub(\"[^0-9]\", \"\", ts[2]) + '-' + ts[1] , ts[5], ts[6], float(ts[4])))\n",
        "            elif len(ts) == 6 or len(ts) == 8:\n",
        "                sent_pairs.append((re.sub(\"[^0-9]\", \"\", ts[1]) + '-' + ts[0] , ts[4], ts[5], float(ts[3])))\n",
        "            else:\n",
        "                print('data format is wrong!!!')\n",
        "    return pd.DataFrame(sent_pairs, columns=[\"year-task\", \"sent_1\", \"sent_2\", \"sim\"])\n",
        "\n",
        "\n",
        "def load_all_sts_dataset():\n",
        "    # Loads all of the STS datasets \n",
        "    stsbenchmarkDir = resourceFile + 'stsbenchmark/'\n",
        "    stscompanionDir = resourceFile + 'stscompanion/'\n",
        "    sts_train = load_sts_dataset(os.path.join(stsbenchmarkDir, \"sts-train.csv\"))    \n",
        "    sts_dev = load_sts_dataset(os.path.join(stsbenchmarkDir, \"sts-dev.csv\"))\n",
        "    sts_test = load_sts_dataset(os.path.join(stsbenchmarkDir, \"sts-test.csv\"))\n",
        "    sts_other = load_sts_dataset(os.path.join(stscompanionDir, \"sts-other.csv\"))\n",
        "    sts_mt = load_sts_dataset(os.path.join(stscompanionDir, \"sts-mt.csv\"))\n",
        "    \n",
        "    sts_all = pd.concat([sts_train, sts_dev, sts_test, sts_other, sts_mt ])\n",
        "    \n",
        "    return sts_all\n",
        "\n",
        "sts_all = load_all_sts_dataset()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# show some sample sts data    \n",
        "sts_all[:5] \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-09 14:58:29--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409630 (400K) [application/x-gzip]\n",
            "Saving to: ‘Stsbenchmark.tar.gz’\n",
            "\n",
            "Stsbenchmark.tar.gz 100%[===================>] 400.03K   425KB/s    in 0.9s    \n",
            "\n",
            "2018-12-09 14:58:31 (425 KB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n",
            "\n",
            "stsbenchmark/\n",
            "stsbenchmark/readme.txt\n",
            "stsbenchmark/sts-test.csv\n",
            "stsbenchmark/correlation.pl\n",
            "stsbenchmark/LICENSE.txt\n",
            "stsbenchmark/sts-dev.csv\n",
            "stsbenchmark/sts-train.csv\n",
            "--2018-12-09 14:58:33--  http://ixa2.si.ehu.es/stswiki/images/e/ee/Stscompanion.tar.gz\n",
            "Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 267977 (262K) [application/x-gzip]\n",
            "Saving to: ‘Stscompanion.tar.gz’\n",
            "\n",
            "Stscompanion.tar.gz 100%[===================>] 261.70K   330KB/s    in 0.8s    \n",
            "\n",
            "2018-12-09 14:58:35 (330 KB/s) - ‘Stscompanion.tar.gz’ saved [267977/267977]\n",
            "\n",
            "stscompanion/\n",
            "stscompanion/readme.txt\n",
            "stscompanion/sts-mt.csv\n",
            "stscompanion/correlation.pl\n",
            "stscompanion/LICENSE.txt\n",
            "stscompanion/sts-other.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year-task</th>\n",
              "      <th>sent_1</th>\n",
              "      <th>sent_2</th>\n",
              "      <th>sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-MSRvid</td>\n",
              "      <td>A plane is taking off.</td>\n",
              "      <td>An air plane is taking off.</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-MSRvid</td>\n",
              "      <td>A man is playing a large flute.</td>\n",
              "      <td>A man is playing a flute.</td>\n",
              "      <td>3.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-MSRvid</td>\n",
              "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
              "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
              "      <td>3.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-MSRvid</td>\n",
              "      <td>Three men are playing chess.</td>\n",
              "      <td>Two men are playing chess.</td>\n",
              "      <td>2.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-MSRvid</td>\n",
              "      <td>A man is playing the cello.</td>\n",
              "      <td>A man seated is playing the cello.</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     year-task                                         sent_1  \\\n",
              "0  2012-MSRvid                         A plane is taking off.   \n",
              "1  2012-MSRvid                A man is playing a large flute.   \n",
              "2  2012-MSRvid  A man is spreading shreded cheese on a pizza.   \n",
              "3  2012-MSRvid                   Three men are playing chess.   \n",
              "4  2012-MSRvid                    A man is playing the cello.   \n",
              "\n",
              "                                              sent_2   sim  \n",
              "0                        An air plane is taking off.  5.00  \n",
              "1                          A man is playing a flute.  3.80  \n",
              "2  A man is spreading shredded cheese on an uncoo...  3.80  \n",
              "3                         Two men are playing chess.  2.60  \n",
              "4                 A man seated is playing the cello.  4.25  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "rF7V-XJ9iq5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### load SIF repository"
      ]
    },
    {
      "metadata": {
        "id": "mr0kmvjvM7ca",
        "colab_type": "code",
        "outputId": "f472a458-7b6d-43d5-f8a7-0c1c887e9033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF # SIF repository\n",
        "\n",
        "\n",
        "wikiWordsPath = resourceFile + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])\n",
        "        \n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SIF'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 2.80 MiB | 16.75 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PbmCvOKNiwf-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### define a class for sentences"
      ]
    },
    {
      "metadata": {
        "id": "awf7uemzM7cg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Sentence:\n",
        "  def __init__(self, sentence):\n",
        "    self.raw = sentence\n",
        "    normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "    self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
        "        \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kUrz9PwumB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### define a class for sentences\n",
        "Divide STS dataset into different domains: 'twitter', 'forums', 'OnWN', 'captions', 'news'"
      ]
    },
    {
      "metadata": {
        "id": "f-atDIPTuuGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stsbenchmarkDir = resourceFile + 'stsbenchmark/'\n",
        "stscompanionDir = resourceFile + 'stscompanion/'\n",
        "\n",
        "sent_pairs = []\n",
        "\n",
        "\n",
        "for sts_string in ['sts-train.csv', 'sts-test.csv', 'sts-dev.csv']:\n",
        "    filename = os.path.join(stsbenchmarkDir, sts_string)\n",
        "    with tf.gfile.GFile(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            ts = line.strip().split(\"\\t\")\n",
        "            domain = ts[0].split('-')[1]\n",
        "            \n",
        "            if domain == 'forum':\n",
        "               domain = 'forums'\n",
        "            \n",
        "            sent_pairs.append((domain , ts[5], ts[6], float(ts[4])))\n",
        "            \n",
        "            \n",
        "with tf.gfile.GFile(os.path.join(stscompanionDir, 'sts-other.csv'), \"r\") as f:\n",
        "    for line in f:\n",
        "        ts = line.strip().split(\"\\t\")\n",
        "        domain = ts[0].split('.')[-1]\n",
        "\n",
        "        if domain == 'OnWN':\n",
        "            domain = 'WordNet' \n",
        "            sent_pairs.append((domain , ts[4], ts[5], float(ts[3])))\n",
        "\n",
        "        if domain == 'tweet-news':\n",
        "            domain = 'tweets' \n",
        "            sent_pairs.append((domain , ts[4], ts[5], float(ts[3])))    \n",
        "\n",
        "            \n",
        "df_all_domains = pd.DataFrame(sent_pairs, columns=[\"domain\", \"sent_1\", \"sent_2\", \"sim\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSzytjMMyK1z",
        "colab_type": "code",
        "outputId": "f004dad9-0a31-4e59-e887-cf2c97d52da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "def load_sts_by_domain():\n",
        "    # Divide STS datasets based on their year and tasks\n",
        "    sts_by_domain = {}\n",
        "    \n",
        "    for domain in df_all_domains['domain'].unique():\n",
        "        print(domain)\n",
        "        indices = [i for i, x in enumerate(list(df_all_domains['domain'])) if x == domain]\n",
        "        \n",
        "        pairs = df_all_domains.iloc[indices]\n",
        "        \n",
        "#         sts_by_domain[domain] = pairs[:maxNr]\n",
        "        sts_by_domain[domain] = pairs\n",
        "        \n",
        "    return sts_by_domain\n",
        "  \n",
        "sts_by_domain = load_sts_by_domain()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "captions\n",
            "forums\n",
            "news\n",
            "WordNet\n",
            "tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SGZwTNZ5zDwr",
        "colab_type": "code",
        "outputId": "e462e012-8e66-4f57-a987-66d58f541656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "domains = sts_by_domain.keys()\n",
        "\n",
        "for domain in domains:\n",
        "    print('size of the dataset', domain, ':', len(sts_by_domain[domain]))\n",
        "# len(sts_by_domain['forums']) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of the dataset captions : 3250\n",
            "size of the dataset forums : 1079\n",
            "size of the dataset news : 4299\n",
            "size of the dataset WordNet : 2061\n",
            "size of the dataset tweets : 750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNlalfk9z15s",
        "colab_type": "code",
        "outputId": "cd6d736d-6e7c-4f3f-dbb7-5d98f47c1ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df_list = ['tweets', 'forums', 'WordNet', 'captions', 'news']\n",
        "\n",
        "freqs=frequencies\n",
        "a =0.001\n",
        "total_freq = sum(freqs.values())\n",
        "\n",
        "model = eval('glove')\n",
        "pre_embedding_dict = {}\n",
        "\n",
        "tokenVecs_dict = {}\n",
        "\n",
        "  \n",
        "for df_string in df_list:\n",
        "    print(df_string)\n",
        "    \n",
        "    df = sts_by_domain[df_string]\n",
        "    sentences1 = [Sentence(s) for s in df['sent_1']]\n",
        "    sentences2 = [Sentence(s) for s in df['sent_2']]\n",
        "\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "    embeddings = []\n",
        "    allTokens = []\n",
        "    for (sent1, sent2) in zip(sentences1, sentences2): \n",
        "\n",
        "        tokens1 =  sent1.tokens\n",
        "        tokens2 =  sent2.tokens\n",
        "\n",
        "        tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "        tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "\n",
        "        weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "        weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "\n",
        "        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "\n",
        "        embeddings.append(embedding1)\n",
        "        embeddings.append(embedding2)\n",
        "\n",
        "        allTokens.extend(tokens1)\n",
        "        allTokens.extend(tokens2)\n",
        "        \n",
        "    pre_embedding_dict[df_string] = embeddings\n",
        "\n",
        "    \n",
        "    allTokens = list(set(allTokens).intersection(model.vocab))\n",
        "\n",
        "    tokenVecs = [model[token] for token in allTokens ]\n",
        "    tokenVecs_dict[df_string] = tokenVecs\n",
        "    \n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "def test_extra_data_sif(model_str, test_df_string, train_df_string_list):\n",
        "    model = eval(model_str)\n",
        "    df = sts_by_domain[test_df_string]\n",
        "    \n",
        "    \n",
        "    target_embedding = np.array(pre_embedding_dict[test_df_string])\n",
        "\n",
        "    extra_embeddings = []\n",
        "    \n",
        "    for i in np.arange(len(train_df_string_list)):\n",
        "        extra_embeddings = extra_embeddings + pre_embedding_dict[train_df_string_list[i]]\n",
        "\n",
        "\n",
        "    X =  np.array(extra_embeddings)\n",
        "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
        "    svd.fit(X)\n",
        "    pc =  svd.components_\n",
        "    embeddings_proj = target_embedding - target_embedding.dot(pc.transpose()) * pc\n",
        "\n",
        "\n",
        "    sims = [cosine_similarity(embeddings_proj[idx*2].reshape(1, -1), \n",
        "                              embeddings_proj[idx*2+1].reshape(1, -1))[0][0] \n",
        "            for idx in range(int(len(embeddings_proj)/2))]\n",
        "\n",
        "\n",
        "    pearson_correlation = round(scipy.stats.pearsonr(sims, df['sim'])[0] * 100,1)\n",
        "\n",
        "    return pearson_correlation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweets\n",
            "forums\n",
            "WordNet\n",
            "captions\n",
            "news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OQI5KJaVa_Cy",
        "colab_type": "code",
        "outputId": "66876589-f624-4a06-f28d-c0057be80031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df_list = ['news', 'captions', 'WordNet', 'forums', 'tweets']\n",
        "print('training corpus presented: large cardinality -> small cardinality')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training corpus presented: large cardinality -> small cardinality\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OIQx49k4lK3d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conduct baseline algorithms and CA"
      ]
    },
    {
      "metadata": {
        "id": "VqmrExSsbCl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (1) corpus-specialized SIF"
      ]
    },
    {
      "metadata": {
        "id": "ST-tGfyCbE2y",
        "colab_type": "code",
        "outputId": "3873bcdf-ab31-4570-d0b3-e68e2a17795b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "SIF_specialize_result = []\n",
        "for item in df_list:\n",
        "    temp = test_extra_data_sif('glove', item, [item])\n",
        "    SIF_specialize_result.append(temp)\n",
        "    print(item, temp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "news 67.5\n",
            "captions 81.2\n",
            "WordNet 82.7\n",
            "forums 60.1\n",
            "tweets 73.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bIEcgWjKbyki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (2) train-from-scratch SIF"
      ]
    },
    {
      "metadata": {
        "id": "q41RG77Z0vRs",
        "colab_type": "code",
        "outputId": "618b99b6-d0e5-4b9e-83f3-967923d54634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "print(df_list)\n",
        "\n",
        "myList = []\n",
        "\n",
        "sif_all_train_result = []\n",
        "\n",
        "countTask = 1\n",
        "for item in df_list:\n",
        "  sif_this_train_result = []\n",
        "\n",
        "  print('======')\n",
        "  myList.append(item)\n",
        "  \n",
        "  print('training SIF on corpus', myList)\n",
        "  print('---')\n",
        "  \n",
        "  for j in np.arange(len(df_list)):\n",
        "#       pearson_correlation = test_extra_data_sif('glove', df_list[j], [item])\n",
        "      pearson_correlation = test_extra_data_sif('glove', df_list[j], myList)\n",
        "\n",
        "      print('testing result of SIF on', df_list[j], ':', pearson_correlation)\n",
        "      sif_this_train_result.append(pearson_correlation)\n",
        "  countTask += 1\n",
        "  \n",
        "  sif_all_train_result.append(sif_this_train_result)\n",
        "print('======')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['news', 'captions', 'WordNet', 'forums', 'tweets']\n",
            "======\n",
            "training SIF on corpus ['news']\n",
            "---\n",
            "testing result of SIF on news : 67.5\n",
            "testing result of SIF on captions : 77.8\n",
            "testing result of SIF on WordNet : 78.0\n",
            "testing result of SIF on forums : 53.8\n",
            "testing result of SIF on tweets : 72.9\n",
            "======\n",
            "training SIF on corpus ['news', 'captions']\n",
            "---\n",
            "testing result of SIF on news : 66.7\n",
            "testing result of SIF on captions : 80.5\n",
            "testing result of SIF on WordNet : 79.5\n",
            "testing result of SIF on forums : 54.6\n",
            "testing result of SIF on tweets : 73.8\n",
            "======\n",
            "training SIF on corpus ['news', 'captions', 'WordNet']\n",
            "---\n",
            "testing result of SIF on news : 66.2\n",
            "testing result of SIF on captions : 80.1\n",
            "testing result of SIF on WordNet : 81.0\n",
            "testing result of SIF on forums : 55.8\n",
            "testing result of SIF on tweets : 74.7\n",
            "======\n",
            "training SIF on corpus ['news', 'captions', 'WordNet', 'forums']\n",
            "---\n",
            "testing result of SIF on news : 66.0\n",
            "testing result of SIF on captions : 80.0\n",
            "testing result of SIF on WordNet : 81.4\n",
            "testing result of SIF on forums : 56.5\n",
            "testing result of SIF on tweets : 74.9\n",
            "======\n",
            "training SIF on corpus ['news', 'captions', 'WordNet', 'forums', 'tweets']\n",
            "---\n",
            "testing result of SIF on news : 65.9\n",
            "testing result of SIF on captions : 80.0\n",
            "testing result of SIF on WordNet : 81.4\n",
            "testing result of SIF on forums : 56.6\n",
            "testing result of SIF on tweets : 74.9\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jYMWc-zccKcm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (3) Conceptor-aided (CA)"
      ]
    },
    {
      "metadata": {
        "id": "ekwuB-6HcRCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def NOT(C, out_mode = \"simple\"):\n",
        "  \"\"\"\n",
        "  Compute NOT operation of conceptor.\n",
        "  \n",
        "  @param R: conceptor matrix\n",
        "  @param out_mode: output mode (\"simple\"/\"complete\")\n",
        "  \n",
        "  @return not_C: NOT C\n",
        "  @return U: eigen vectors of not_C\n",
        "  @return S: eigen values of not_C\n",
        "  \"\"\"\n",
        "  \n",
        "  dim = C.shape[0]\n",
        "  \n",
        "  not_C = np.eye(dim) - C\n",
        "  \n",
        "\n",
        "  if out_mode == \"complete\":\n",
        "    U, S, _ = np.linalg.svd(not_C)\n",
        "    return not_C, U, S\n",
        "  else:\n",
        "    return not_C\n",
        "  \n",
        "def AND(C, B, out_mode = \"simple\", tol = 1e-14):\n",
        "  \"\"\"\n",
        "  Compute AND Operation of two conceptor matrices\n",
        "  \n",
        "  @param C: a conceptor matrix\n",
        "  @param B: another conceptor matrix\n",
        "  @param out_mode: output mode (\"simple\"/\"complete\")\n",
        "  @param tol: adjust parameter for almost zero\n",
        "  \n",
        "  @return C_and_B: C AND B\n",
        "  @return U: eigen vectors of C_and_B\n",
        "  @return S: eigen values of C_and_B\n",
        "  \"\"\"\n",
        "  \n",
        "  dim = C.shape[0]\n",
        "  \n",
        "  UC, SC, _ = np.linalg.svd(C)\n",
        "  UB, SB, _ = np.linalg.svd(B)\n",
        "  \n",
        "  num_rank_C = np.sum((SC > tol).astype(float))\n",
        "  num_rank_B = np.sum((SB > tol).astype(float))\n",
        "  \n",
        "  UC0 = UC[:, int(num_rank_C):]\n",
        "  UB0 = UB[:, int(num_rank_B):]\n",
        "  \n",
        "  W, sigma, _ = np.linalg.svd(UC0.dot(UC0.T) + UB0.dot(UB0.T))\n",
        "  num_rank_sigma = np.sum((sigma > tol).astype(float))\n",
        "  Wgk = W[:, int(num_rank_sigma):]\n",
        "  \n",
        "  C_and_B = Wgk.dot(np.linalg.inv(Wgk.T.dot(np.linalg.pinv(C, tol) + np.linalg.pinv(B, tol) - np.eye(dim)).dot(Wgk))).dot(Wgk.T)\n",
        "  \n",
        "\n",
        "  if out_mode ==\"complete\":\n",
        "    U, S, _ = np.linalg.svd(C_and_B)\n",
        "    return C_and_B, U, S\n",
        "  else:\n",
        "    return C_and_B\n",
        "  \n",
        "def OR(R, Q, out_mode = \"simple\"):\n",
        "  \"\"\"\n",
        "  Compute OR operation of two conceptor matrices\n",
        "  \n",
        "  @param R: a conceptor matrix\n",
        "  @param Q: another conceptor matrix\n",
        "  @param out_mode: output mode (\"simple\"/\"complete\")\n",
        "  \n",
        "  @return R_or_Q: R OR Q\n",
        "  @return U: eigen vectors of R_or_Q\n",
        "  @return S: eigen values of R_or_Q\n",
        "  \"\"\"\n",
        "  \n",
        "  R_or_Q = NOT(AND(NOT(R), NOT(Q)))\n",
        "\n",
        "\n",
        "  if out_mode == \"complete\":\n",
        "    U, S, _ = np.linalg.svd(R_or_Q)\n",
        "    return R_or_Q, U, S\n",
        "  else:\n",
        "    return R_or_Q\n",
        "  \n",
        "  \n",
        "def train_Conceptor(wordVecModel_str, wordList, alpha = 1, plotSpectrum = False):\n",
        "    # compute the conceptor with the word list provided\n",
        "    \n",
        "    wordVecModel = eval(wordVecModel_str)    \n",
        "    word_in_wiki_and_model = set(list(wordVecModel.vocab)).intersection(wordList)\n",
        "\n",
        "    x_collector_indices = []\n",
        "\n",
        "\n",
        "    for word in word_in_wiki_and_model:\n",
        "        x_collector_indices.append(wordVecModel.vocab[word].index)\n",
        "\n",
        "    # put the word vectors in columns\n",
        "    x_collector = wordVecModel.vectors[x_collector_indices,:].T       \n",
        "        \n",
        "    \n",
        "    nrWords = x_collector.shape[1] # number of total words\n",
        "    \n",
        "    \n",
        "    R = x_collector.dot(x_collector.T) / nrWords # calculate the correlation matrix\n",
        "    \n",
        "    C = R @ np.linalg.inv(R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    return C\n",
        "\n",
        "def test_stopwords_conceptor(model_str, test_df_string, C_stopwords = None):\n",
        "    ''' \n",
        "    Inputs:\n",
        "    (1) model_str: word vector model, e.g., 'glove'\n",
        "    (2) test_df_string: testing corpus, e.g., 'forums'\n",
        "    (3) C_stopwords: a conceptor trained with stop words\n",
        "\n",
        "    Output:\n",
        "    (4) pearson_correlation: pearson correlation coefficient of the testing corpus\n",
        "    '''\n",
        "  \n",
        "    if C_stopwords is None:\n",
        "        print('no conceptor is loaded!!')\n",
        "        \n",
        "    model = eval(model_str)\n",
        "    df = sts_by_domain[test_df_string]\n",
        "    \n",
        "    target_embedding = np.array(pre_embedding_dict[test_df_string])\n",
        "\n",
        "        \n",
        "    update_negC = NOT(C_stopwords)\n",
        "\n",
        "    embeddings_proj = update_negC.dot(target_embedding.T).T\n",
        "\n",
        "    \n",
        "    sims = [cosine_similarity(embeddings_proj[idx*2].reshape(1, -1), embeddings_proj[idx*2+1].reshape(1, -1))[0][0] for idx in range(int(len(embeddings_proj)/2))]\n",
        "\n",
        "\n",
        "    pearson_correlation = round(scipy.stats.pearsonr(sims, df['sim'])[0] * 100,1)\n",
        "\n",
        "    return pearson_correlation\n",
        "\n",
        "def test_updated_conceptor(model_str, test_df_string, train_df_string_list, C_prev = None, alpha = 1):\n",
        "    ''' \n",
        "    Inputs:\n",
        "    (1) model_str: word vector model, e.g., 'glove'\n",
        "    (2) test_df_string: testing corpus, e.g., 'forums'\n",
        "    (3) train_df_string_list: a list of training corpus, e.g., [forums', 'OnWN']\n",
        "    (4) C_stopwords: a conceptor trained with stop words\n",
        "    (5) C_prev: the previous conceptor\n",
        "    \n",
        "    Output:\n",
        "    (1) updated_C: updated conceptor based on the training corpus and the previous conceptor\n",
        "    (2) pearson_correlation: pearson correlation coefficient of the testing corpus\n",
        "    '''\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    df = sts_by_domain[test_df_string]\n",
        "    \n",
        "    \n",
        "    target_embedding = np.array(pre_embedding_dict[test_df_string])\n",
        "\n",
        "    X_list = []\n",
        "    \n",
        "    for i in np.arange(len(train_df_string_list)):\n",
        "#         token_vecs = token_vecs + tokenVecs_dict[train_df_string_list[i]]\n",
        "        X_list = X_list + pre_embedding_dict[train_df_string_list[i]]\n",
        "\n",
        "\n",
        "    X = np.array(X_list)\n",
        "    \n",
        "    R = (X.T).dot(X) / X.shape[0]\n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))    # calculate the conceptor matrix\n",
        "\n",
        "    if C_prev is None:\n",
        "        print('no previous C was loaded!!')\n",
        "        updated_C = C \n",
        "    else:\n",
        "        updated_C = OR(C, C_prev)\n",
        "\n",
        "    update_negC = NOT(updated_C)\n",
        "    \n",
        "    \n",
        "    embeddings_proj = update_negC.dot(target_embedding.T).T\n",
        "\n",
        "    \n",
        "    sims = [cosine_similarity(embeddings_proj[idx*2].reshape(1, -1), embeddings_proj[idx*2+1].reshape(1, -1))[0][0] for idx in range(int(len(embeddings_proj)/2))]\n",
        "\n",
        "\n",
        "    pearson_correlation = round(scipy.stats.pearsonr(sims, df['sim'])[0] * 100,1)\n",
        "\n",
        "    return updated_C, pearson_correlation\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biBVOT42cl4v",
        "colab_type": "code",
        "outputId": "6156ae05-92ae-4b8b-ad5b-ac3341d53725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "\n",
        "# stopwordPath = resourceFile + 'stopwords/en/' + 'corenlp_hardcoded.txt'\n",
        "# stopwordPath = resourceFile + 'stopwords/en/' + 'ranksnl_large.txt'\n",
        "\n",
        "# STOP = []\n",
        "# with open(stopwordPath, \"r+\") as f:\n",
        "#     for line in f:\n",
        "#         STOP.append(line.split('\\n')[0])\n",
        "STOP = [word.replace(\"'\", \"\") for word in STOP]        \n",
        "C_stopword = train_Conceptor('glove', STOP)\n",
        "\n",
        "\n",
        "print('----')\n",
        "print('0 training corpus ')\n",
        "conceptor_zero_corpus_results = []\n",
        "for j in np.arange(len(df_list)):\n",
        "    pearson_correlation = test_stopwords_conceptor('glove', df_list[j], C_stopword)\n",
        "    print(df_list[j], pearson_correlation)\n",
        "    conceptor_zero_corpus_results.append(pearson_correlation)\n",
        "print('----')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "----\n",
            "0 training corpus \n",
            "news 65.6\n",
            "captions 79.8\n",
            "WordNet 82.5\n",
            "forums 61.5\n",
            "tweets 75.2\n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L3LYdBWPcrNm",
        "colab_type": "code",
        "outputId": "1b442a2f-70bd-496e-a1eb-e4f8dc12bb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "myList = []\n",
        "\n",
        "countTask = 1\n",
        "C_prev_stopword = C_stopword\n",
        "C_prev_zero = np.eye(300) * 0\n",
        "\n",
        "ca_all_train_result = []\n",
        "\n",
        "no_stopword_ca_all_train_result = []\n",
        "\n",
        "for item in df_list:\n",
        "    print('======')\n",
        "    myList = [item]\n",
        "    print('training CA encoder on corpus', myList)\n",
        "    print('---')\n",
        "\n",
        "\n",
        "    ca_this_train_result = []\n",
        "    no_stopword_ca_this_train_result = []\n",
        "    for j in np.arange(len(df_list)):\n",
        "        _, ca_pearson_correlation = test_updated_conceptor('glove', df_list[j], myList, C_prev_stopword )\n",
        "        _, no_stopword_ca_pearson_correlation = test_updated_conceptor('glove', df_list[j], myList, C_prev_zero )\n",
        "        ca_this_train_result.append(ca_pearson_correlation)\n",
        "        no_stopword_ca_this_train_result.append(no_stopword_ca_pearson_correlation)\n",
        "        print(df_list[j], ca_pearson_correlation)\n",
        "\n",
        "\n",
        "    ca_all_train_result.append(ca_this_train_result)\n",
        "    no_stopword_ca_all_train_result.append(no_stopword_ca_this_train_result)\n",
        "    \n",
        "    \n",
        "    C_prev_stopword, _ = test_updated_conceptor('glove', item, myList,  C_prev_stopword )\n",
        "    C_prev_zero, _ = test_updated_conceptor('glove', item, myList,  C_prev_zero )\n",
        "    \n",
        "    \n",
        "    countTask += 1\n",
        "print('======')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======\n",
            "training CA encoder on corpus ['news']\n",
            "---\n",
            "news 69.8\n",
            "captions 80.4\n",
            "WordNet 82.1\n",
            "forums 62.2\n",
            "tweets 76.2\n",
            "======\n",
            "training CA encoder on corpus ['captions']\n",
            "---\n",
            "news 69.7\n",
            "captions 84.4\n",
            "WordNet 81.9\n",
            "forums 61.9\n",
            "tweets 76.3\n",
            "======\n",
            "training CA encoder on corpus ['WordNet']\n",
            "---\n",
            "news 69.6\n",
            "captions 84.6\n",
            "WordNet 84.2\n",
            "forums 61.9\n",
            "tweets 76.2\n",
            "======\n",
            "training CA encoder on corpus ['forums']\n",
            "---\n",
            "news 69.6\n",
            "captions 84.7\n",
            "WordNet 83.9\n",
            "forums 63.1\n",
            "tweets 76.1\n",
            "======\n",
            "training CA encoder on corpus ['tweets']\n",
            "---\n",
            "news 69.7\n",
            "captions 84.7\n",
            "WordNet 83.8\n",
            "forums 63.3\n",
            "tweets 76.1\n",
            "======\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "riNtUOCzcwB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compare the baseline and CA results"
      ]
    },
    {
      "metadata": {
        "id": "oE_rZLy5tSwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.rc('font', family='DejaVu', serif='Times')\n",
        "plt.rc('text', usetex=False)\n",
        "plt.rc('xtick', labelsize=8)\n",
        "plt.rc('ytick', labelsize=8)\n",
        "plt.rc('axes', labelsize=8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNk26o-TpQrb",
        "colab_type": "code",
        "outputId": "acc27260-71e8-4dde-e05a-33b69be32e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "concatResult = np.array(list(ca_all_train_result) + (list(sif_all_train_result))) # for the convenience of plot\n",
        "\n",
        "sif_all_train_result = np.array(sif_all_train_result)\n",
        "ca_all_train_result = np.array(ca_all_train_result)\n",
        "no_stopword_ca_all_train_result = np.array(no_stopword_ca_all_train_result)\n",
        "\n",
        "\n",
        "width = 6.3\n",
        "height = width / 1.618 / 5\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(left=.05, bottom=.05, right=.99, top= 0.97, wspace = 0.3)\n",
        "\n",
        "\n",
        "for i in range(len(df_list)):\n",
        "    # i = 0    \n",
        "    this_ax = fig.add_subplot('15' + str(i + 1))\n",
        "\n",
        "    this_ax.axhline(y= SIF_specialize_result[i] , color = 'k', linestyle = ':',label = 'corpus specialized SIF')\n",
        "\n",
        "    this_ax.plot(np.array([1,2,3,4,5]), \n",
        "            sif_all_train_result[:,i], \n",
        "            linewidth=2, \n",
        "            linestyle='-', \n",
        "            marker = '^',\n",
        "            markersize=4,\n",
        "            label='train-from-scratch SIF'\n",
        "            );\n",
        "\n",
        "    this_ax.plot(np.array([1,2,3,4,5]), \n",
        "            ca_all_train_result[:,i], \n",
        "            linewidth=2, \n",
        "            linestyle='-', \n",
        "            marker = 's',\n",
        "            markersize=4,\n",
        "            label='CA'\n",
        "            );\n",
        "\n",
        "    if i == math.floor(len(df_list)/2):\n",
        "        legend = this_ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.3), ncol= 3 ,fontsize='8')\n",
        "\n",
        "    if i == 0:\n",
        "        this_ax.set_ylabel(r\"PCC\")\n",
        "        this_ax.set_xlabel(r\"first $n$ training\" + \"\\n corpora used\")\n",
        "\n",
        "\n",
        "    this_ax.set_title(df_list[i].capitalize() )\n",
        "\n",
        "    plt.setp([this_ax], xticks=[1,2,3,4,5])\n",
        "\n",
        "    plt.sca(this_ax)\n",
        "\n",
        "    minMax = [math.floor(np.min(concatResult[:, i]) - 2), math.ceil(np.max(concatResult[:, i]) + 2)]\n",
        "    this_ax.set_ylim(minMax)\n",
        "    plt.yticks(minMax)\n",
        "\n",
        "fig.set_size_inches(width, height)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['DejaVu'] not found. Falling back to DejaVu Sans\n",
            "  (prop.get_family(), self.defaultFamily[fontext]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAB/CAYAAAC9vIj2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKFAsKrgGXwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f19fa01af28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ukpYhWjVe3o1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}